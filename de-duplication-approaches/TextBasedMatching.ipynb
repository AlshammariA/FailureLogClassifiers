{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text-Based Matching"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import csv\n",
    "import re\n",
    "import xml.etree.ElementTree as ET\n",
    "import filecmp\n",
    "from lxml import etree\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "import collections\n",
    "from itertools import count, groupby\n",
    "import ast\n",
    "import warnings\n",
    "from collections import Counter\n",
    "from tqdm import tqdm\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readXMLFile(filePath):\n",
    "    parser = etree.XMLParser(strip_cdata=False,recover=True)\n",
    "    with open(filePath, \"rb\") as source:\n",
    "        tree = etree.parse(source, parser=parser)\n",
    "    xmlroot = tree.getroot()\n",
    "    return xmlroot\n",
    "\n",
    "def getSummaryFiles(filesPath):\n",
    "    allFiles = []\n",
    "    for path, subdirs, files in os.walk(filesPath):\n",
    "        for file in files:\n",
    "            if (file.startswith('summary-of-')):\n",
    "                allFiles.append(os.path.join(path,file))\n",
    "    return allFiles\n",
    "\n",
    "def find_index_starts_with(stacktraces, stoppedLines):\n",
    "    index = next((index for index, element in enumerate(stacktraces) if any(element.startswith(prefix) for prefix in stoppedLines)), -1)\n",
    "    return index\n",
    "\n",
    "def remove_elements_starts_with(stacktraces, removedLines):\n",
    "    return [element for element in stacktraces if not any(element.startswith(prefix) for prefix in removedLines)]\n",
    "\n",
    "\n",
    "def getmutantsFailures(xmlFile,testName,className):\n",
    "    execludedLines = ['java.lang.invoke.LambdaForm','sun.reflect.GeneratedMethodAccessor','sun.reflect.GeneratedConstructorAccessor','com.sun.proxy.']\n",
    "    stoppedLines = ['junit.framework.TestCase.runBare(','sun.reflect.NativeMethodAccessorImpl.invoke0(','org.junit.rules.ExternalResource$1.evaluate(']\n",
    "    result = []\n",
    "    for mutant in xmlFile.iter('mutant'):\n",
    "        if (mutant.find('mutant_name').attrib['status'] == 'KILLED'):\n",
    "            mutantException = mutant.find('mutant_exception').text\n",
    "\n",
    "            lines = []\n",
    "            for line in mutant.iter('line'):\n",
    "                stackTrace = line.text.replace(\" \", \"\").replace(\"\\t\", \"\").replace(\"\\n\", \"\")\n",
    "                lines.append(stackTrace.strip())\n",
    "\n",
    "            \n",
    "            if(all(not any(item.startswith(prefix) for prefix in [testName,className]) for item in lines)):\n",
    "                ind = find_index_starts_with(lines, stoppedLines)\n",
    "                if (ind > 0):\n",
    "                    lines = lines[:ind]\n",
    "            \n",
    "            # remove non-determinist lines\n",
    "            lines = remove_elements_starts_with(lines, execludedLines)\n",
    "            result.append(mutantException + '|#|'+'|'.join(lines) )\n",
    "    return result\n",
    "\n",
    "def getTestFailure(failure,testName,className):\n",
    "    execludedLines = ['java.lang.invoke.LambdaForm','sun.reflect.GeneratedMethodAccessor','sun.reflect.GeneratedConstructorAccessor','com.sun.proxy.']\n",
    "    stoppedLines = ['junit.framework.TestCase.runBare(','sun.reflect.NativeMethodAccessorImpl.invoke0(','org.junit.rules.ExternalResource$1.evaluate(']\n",
    "\n",
    "    failureExc =  failure.find('test_exception').text\n",
    "    lines = []\n",
    "    for line in failure.iter('line'):\n",
    "        stackTrace = line.text.replace(\" \", \"\").replace(\"\\t\", \"\").replace(\"\\n\", \"\")\n",
    "        lines.append(stackTrace.strip())\n",
    "    \n",
    "    if(all(not any(item.startswith(prefix) for prefix in [testName,className]) for item in lines)):\n",
    "        ind = find_index_starts_with(lines, stoppedLines)\n",
    "        if (ind > 0):\n",
    "            lines = lines[:ind]\n",
    "    \n",
    "    # remove non-deterministic lines\n",
    "    lines = remove_elements_starts_with(lines, execludedLines)\n",
    "        \n",
    "    return failureExc + '|#|'+'|'.join(lines) \n",
    "\n",
    "def most_frequent(List):\n",
    "    occurence_count = Counter(List)\n",
    "    if (len(List)>0):\n",
    "        return occurence_count.most_common(1)[0][0],occurence_count.most_common(1)[0][1]\n",
    "    else:\n",
    "        return 'NA',0\n",
    "\n",
    "def getTotalMutants(data_df):\n",
    "    totalMutants = []\n",
    "    for test in data_df['Test'].unique():\n",
    "        perProjectPerTest = data_df[data_df['Test'] == test]\n",
    "        totalMutants.append(int(perProjectPerTest['TotalMutants'].unique()[0]))\n",
    "    return totalMutants\n",
    "\n",
    "def getStat(data_df):\n",
    "    if (len(data_df)>0):\n",
    "        return max(data_df),min(data_df),round(np.median(sorted(data_df)[int(len(data_df)/2)]),0)\n",
    "    else:\n",
    "        return 0,0,0\n",
    "\n",
    "\n",
    "def getChangedFile(filesDF,project,bugID):\n",
    "    perFile = filesDF[(filesDF['project']==project)&(filesDF['bugId']==int(bugID))]\n",
    "    return perFile['fileName'].unique()\n",
    "\n",
    "\n",
    "def latexFormat(data):\n",
    "    for i, r in data.iterrows():\n",
    "        perProject = []\n",
    "        for value in r:\n",
    "            if (str(value).endswith('-%') or str(value).endswith('-')):\n",
    "                perProject.append('')\n",
    "            elif (str(value).endswith('%')):\n",
    "                perProject.append(str(value).split('%')[0]+'\\\\%')\n",
    "            elif(str(value).endswith('nan')):\n",
    "                perProject.append('')\n",
    "            else:\n",
    "                perProject.append(value)\n",
    "        \n",
    "        for p in perProject:\n",
    "                try:\n",
    "                    int(p)\n",
    "                    perProject[perProject.index(p)] = '{:,.0f}'.format(p)\n",
    "                except ValueError:\n",
    "                    pass\n",
    "        \n",
    "        if (i%2 == 1):\n",
    "            print ('&'.join(['\\cellcolor{gray!6}{'+str(r)+'}' for r in perProject])+'\\\\\\\\')\n",
    "        else:\n",
    "            print ('&'.join([str(r) for r in perProject])+'\\\\\\\\')\n",
    "            \n",
    "def getSetOfFailures(testFailures):\n",
    "    updatedFailures = {}\n",
    "    for v in set(testFailures.values()):\n",
    "        perFailure = {k:v1 for k, v1 in testFailures.items() if v1 == v}\n",
    "        totalFailures = [k for k in perFailure.keys()]\n",
    "        if (len(totalFailures)>1):\n",
    "            total = sum([int(k.rsplit('|',1)[1]) for k in totalFailures])\n",
    "            newKey = totalFailures[0].rsplit('|',1)[0] + '|' + str(total)\n",
    "            updatedFailures[newKey] = v\n",
    "        else:\n",
    "            updatedFailures[totalFailures[0]] = v\n",
    "    return updatedFailures\n",
    "\n",
    "\n",
    "def appendSumRow(data,ignoreColumnsNames):\n",
    "    sumRows = {}\n",
    "    for c in data.columns:\n",
    "        if (c not in ignoreColumnsNames):\n",
    "            sumRows [c] = data[c].sum()\n",
    "\n",
    "    updated_data = data.append(sumRows, ignore_index=True)\n",
    "\n",
    "    for col in updated_data.columns:\n",
    "        # Check if the column is of type float and if all its non-NaN values are integers\n",
    "        if updated_data[col].dtype == \"float64\" and all(updated_data[col].dropna().apply(lambda x: x.is_integer())):\n",
    "            updated_data[col] = updated_data[col].astype(int)\n",
    "    \n",
    "    return updated_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = 'PATH/TO/22projects' # change this to summary-of files (22 projects)\n",
    "logs = getSummaryFiles(data)\n",
    "output = 'Result'\n",
    "Path(output).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "projectNames = {\"spring-boot\":\"spring-projects-spring-boot\",\n",
    "                \"alluxio\" : \"Alluxio-alluxio\",\n",
    "                \"http-request\": \"kevinsawicki-http-request\",\n",
    "                \"hbase\" : \"apache-hbase\",\n",
    "                \"ambari\": \"apache-ambari\",\n",
    "                \"java-webSocket\" : \"tootallnate-java-websocket\",\n",
    "                \"wildfly\": \"wildfly-wildfly\",\n",
    "                \"okhttp\":\"square-okhttp\",\n",
    "                \"hector\" : \"hector-client-hector\",\n",
    "                \"wro4j\": \"wro4j-wro4j\",\n",
    "                \"incubator-dubbo\" : \"apache-incubator-dubbo\",\n",
    "                \"logback\" : \"qos-ch-logback\",\n",
    "                \"activiti\" : \"activiti-activiti\",\n",
    "                \"httpcore\" : \"apache-httpcore\",\n",
    "                \"commons-exec\" : \"apache-commons-exec\",\n",
    "                \"io-undertow\" : \"undertow-io-undertow\",\n",
    "                \"orbit\" : \"orbit-orbit\",\n",
    "                \"assertj-core\" : \"assertj-core\",\n",
    "                \"achilles\" : \"doanduyhai-Achilles\",\n",
    "                \"handlebars.java\" : \"handlebars.java\",\n",
    "                \"elastic-job-lite\" : \"elasticjob-elastic-job-lite\",\n",
    "                \"zxing\" : \"zxing-zxing\",\n",
    "                \"ninja\" : \"ninja-ninja\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1) Get the result per failure per test ... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 583/583 [00:05<00:00, 113.23it/s]\n"
     ]
    }
   ],
   "source": [
    "fullResult = []\n",
    "repetitive = {}\n",
    "for log in tqdm(logs):\n",
    "    if (os.path.getsize(log) >0):\n",
    "        # if (log.endswith('summary-of-com.squareup.okhttp.internal.http.HttpResponseCacheTest.responseSourceHeaderFetched.xml')):\n",
    "            logXML = readXMLFile(log)\n",
    "            test_name = log.rsplit('/',1)[1].split('summary-of-')[1].rsplit('.xml')[0]\n",
    "            mutantsFailures = getmutantsFailures(logXML,test_name,test_name.rsplit('.',1)[0])\n",
    "            \n",
    "            testFailures = {}\n",
    "            for failure in logXML.iter('test'):\n",
    "                perProject = []\n",
    "                Failure = getTestFailure(failure,test_name,test_name.rsplit('.',1)[0])\n",
    "                k = failure.find('test_name').attrib['project']+'|'+failure.find('test_name').attrib['id']+'|'+failure.find('test_name').attrib['frequency']\n",
    "                testFailures[k] =Failure\n",
    "            \n",
    "            setTestFailures = getSetOfFailures(testFailures) # This to get the set of failures ... \n",
    "\n",
    "            for k,Failure in setTestFailures.items():\n",
    "                perProject = []\n",
    "                perProject.append(k.split('|')[0]) # project name\n",
    "                perProject.append(test_name)\n",
    "                perProject.append(k.split('|')[1]) # test id\n",
    "                perProject.append(k.split('|')[2]) # failure ferq\n",
    "                perProject.append(Failure.split('|#|')[0])\n",
    "\n",
    "                perProject.append(1 if test_name in Failure else 0) # test name in stacktrace lines .. \n",
    "                perProject.append(1 if test_name.rsplit('.',1)[0] in Failure else 0) # test classname in stacktrace lines .. \n",
    "                perProject.append(len(Failure.split('|#|')[1].split('|'))) # How many lines ... \n",
    "                perProject.append(len(mutantsFailures)) # total killed mutants\n",
    "                perProject.append(len(set(mutantsFailures)))\n",
    "                perProject.append(len([i for i in mutantsFailures if i.startswith(Failure.split('|#|')[0]+'|#|')])) # total match with exception\n",
    "                perProject.append(len([i for i in mutantsFailures if i.endswith('|#|' + Failure.split('|#|')[1])])) # total match with stacktraces\n",
    "                perProject.append(mutantsFailures.count(Failure)) # total match\n",
    "\n",
    "                mostMutantExc = \"NA\"\n",
    "                mostMutantFreq = 0\n",
    "                if (len(mutantsFailures)>0):\n",
    "                    mostMutantExc, mostMutantFreq = most_frequent([x.split('|#|')[0] for x in mutantsFailures])\n",
    "                perProject.append(mostMutantExc) # most exception in mutants \n",
    "                perProject.append(mostMutantFreq) # exception rate  \n",
    "\n",
    "                fullResult.append(perProject)\n",
    "\n",
    "                # Repetitive failures \n",
    "                if (len(mutantsFailures)>0):\n",
    "                    r_key = k.split('|')[0] + '|' + test_name + '|' + k.split('|')[1] + '|' + k.split('|')[2]\n",
    "                    repetitive[r_key] = Failure\n",
    "\n",
    "\n",
    "# dataframe columns .. \n",
    "columnList = ['Project','Test','TestID','FailureFreq','FailureException','TestNameInStacktrace','TestClassNameInStacktrace','TotalStacktraceLines','TotalMutants','set(TotalMutants)','TotalMatchException','TotalMatchStacktrace','TotalMatch',\n",
    "              'MostExceptionInMutants','MostExceptionInMutantsFreq']\n",
    "finalResult = pd.DataFrame(fullResult,columns=columnList)\n",
    "finalResult.to_csv(output+'/PerFailureResult.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2) Find Repetitive Flaky Failures ... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "projectsList = [v.split('|')[0] for v in repetitive.keys()]\n",
    "resultRQ1 = []\n",
    "for p in set(projectsList):\n",
    "    # if ('hbase' in p):\n",
    "        perProjectData = {k:v for k, v in repetitive.items() if k.startswith(p+'|')}\n",
    "        \n",
    "        tests = list([k.split('|')[1] for k in perProjectData.keys()])\n",
    "\n",
    "        \n",
    "        perFailures = {k.rsplit('|',1)[0]:k.rsplit('|',1)[1] for k in perProjectData.keys()}\n",
    "        totalFlakyFailures = [int(f) for f in perFailures.values()]\n",
    "\n",
    "        FlakesOnce = len([k for k in perProjectData.keys() if k.endswith('|1')])\n",
    "\n",
    "        reverseDict = {}\n",
    "        for k, v in perProjectData.items():\n",
    "            if (v not in reverseDict.keys()):\n",
    "                reverseDict[v] = int(k.rsplit('|',1)[1])\n",
    "            else:\n",
    "                reverseDict[v] = reverseDict[v] + int(k.rsplit('|',1)[1])\n",
    "            \n",
    "        allFlakesOnce = len([v for v in reverseDict.values() if v == 1])\n",
    "        allFlakesMore= sum([v for v in reverseDict.values() if v >1])\n",
    "\n",
    "\n",
    "\n",
    "        # new version of Dictionary\n",
    "        newPerProject ={}\n",
    "        avoidLines = [t + '(' for t in tests]\n",
    "        for k,v in perProjectData.items():\n",
    "            e = v.split('|#|')[0]\n",
    "            traces = v.split('|#|')[1].split('|')\n",
    "\n",
    "            filtered_traces = [item for item in traces if not any(item.startswith(prefix) for prefix in avoidLines)]\n",
    "            \n",
    "            newPerProject[k] = e + '|#|' + '|'.join(filtered_traces)\n",
    "\n",
    "        reverseDictWithoutTests = {}\n",
    "        for k, v in newPerProject.items():\n",
    "            if (v not in reverseDictWithoutTests.keys()):\n",
    "                reverseDictWithoutTests[v] = int(k.rsplit('|',1)[1])\n",
    "            else:\n",
    "                reverseDictWithoutTests[v] = reverseDictWithoutTests[v] + int(k.rsplit('|',1)[1])\n",
    "\n",
    "        allFlakesOnceWithoutTests = len([v for v in reverseDictWithoutTests.values() if v == 1])\n",
    "        allFlakesMorWithoutTests = sum([v for v in reverseDictWithoutTests.values() if v >1])\n",
    "\n",
    "\n",
    "        resultRQ1.append([p,\n",
    "                        len(set(tests)),\n",
    "                        sum(totalFlakyFailures),\n",
    "                        len(perProjectData),\n",
    "                        FlakesOnce,\n",
    "                        sum(totalFlakyFailures) - FlakesOnce,\n",
    "                        allFlakesOnceWithoutTests,\n",
    "                        allFlakesMorWithoutTests])\n",
    "\n",
    "resultRQ1_df = pd.DataFrame(resultRQ1,columns=['Project','Tests','Flaky Failures','Set(FlakyFailures)','withTest[1]','withTest(1:n)','acrossTestWithoutTestNames[1]','acrossTestWithoutTestNames(1:n)']).sort_values(by=['Tests'], ascending=False)\n",
    "\n",
    "# Add the sum row \n",
    "repetitiveData = appendSumRow(resultRQ1_df,['Project'])\n",
    "repetitiveData.to_csv(output+'/RepetitiveFlakyFailure.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3) Text-Based Approach Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.read_csv('Result/PerFailureResult.csv', index_col=False)\n",
    "summary = []\n",
    "exception_summary = []\n",
    "\n",
    "for p in result['Project'].unique():\n",
    "    perProject = result[(result['Project']== p)&(result['TotalMutants'].astype(int)>0)]\n",
    "    if (len(perProject)>0):\n",
    "\n",
    "        # get the total number of tests flakes once ... \n",
    "        TP_Data = perProject[(perProject['TotalMatch'].astype(int)==0) & (perProject['FailureFreq'].astype(int)>1)]\n",
    "\n",
    "        FN_Data = perProject[(perProject['TotalMatch'].astype(int)>0) | (perProject['FailureFreq'].astype(int)==1)]\n",
    "        \n",
    "        FP_Data = perProject[perProject['TotalMatch']>0]\n",
    "\n",
    "        \n",
    "        # TN\n",
    "        tn_tests = 0\n",
    "        tn_failures = 0\n",
    "        for t in perProject['Test'].unique():\n",
    "            perProjectPerTest = perProject[perProject['Test']==t]\n",
    "\n",
    "            TotalMutants = perProjectPerTest['TotalMutants'].tolist()[0]\n",
    "            tn_failures = tn_failures + (TotalMutants - int (perProjectPerTest['TotalMatch'].sum()))\n",
    "            if (TotalMutants > perProjectPerTest['TotalMatch'].sum()):\n",
    "                tn_tests = tn_tests + 1\n",
    "\n",
    "\n",
    "        # Get the result \n",
    "        summary.append([p,\n",
    "                        len(perProject['Test'].unique()),\n",
    "                        perProject.drop_duplicates(subset='Test', keep='first')['TotalMutants'].sum(),\n",
    "                        perProject['FailureFreq'].sum(),\n",
    "                        \n",
    "                        # Single and de-duplicate failures .. \n",
    "                        # len((perProject[perProject['FailureFreq'].astype(int)==1])),\n",
    "                        # perProject['FailureFreq'].sum() -  len((perProject[perProject['FailureFreq'].astype(int)==1])),\n",
    "                        \n",
    "                        perProject.drop_duplicates(subset='Test', keep='first')['set(TotalMutants)'].sum(),\n",
    "                        len(perProject),\n",
    "                        \n",
    "\n",
    "                        # TP\n",
    "                        TP_Data['FailureFreq'].sum(),\n",
    "                        \n",
    "                        # FN\n",
    "                        FN_Data['FailureFreq'].sum(),\n",
    "\n",
    "                        # FP\n",
    "                        FP_Data['TotalMatch'].sum(),\n",
    "\n",
    "                        # TN\n",
    "                        tn_failures,\n",
    "\n",
    "                        len(TP_Data['Test'].unique()),\n",
    "                        len(FN_Data['Test'].unique()),\n",
    "                        len(FP_Data['Test'].unique()),\n",
    "                        tn_tests,\n",
    "\n",
    "                        \n",
    "                        # P\n",
    "                        str(math.floor(TP_Data['FailureFreq'].sum()/(TP_Data['FailureFreq'].sum()+FP_Data['TotalMatch'].sum())*100) if len(TP_Data['FailureFreq'])>0 else 0 )+'%',\n",
    "\n",
    "                        # R\n",
    "                        str(math.floor(TP_Data['FailureFreq'].sum()/(TP_Data['FailureFreq'].sum()+FN_Data['FailureFreq'].sum())*100) if len(TP_Data['FailureFreq'])>0 else 0 )+'%',\n",
    "                        \n",
    "                        # # Spes.\n",
    "                        str(math.floor(tn_failures/(tn_failures+FP_Data['TotalMatch'].sum())*100))+'%'\n",
    "                        \n",
    "                        ])\n",
    "\n",
    "\n",
    "columnsList = ['Project','Test','True','Flaky','set(True)','set(Flaky)','TP','FN','FP','TN','t(tp)','t(fn)','t(fp)','t(tn)','P','R','SP']\n",
    "textMatching = pd.DataFrame(summary,columns=columnsList).sort_values(by=['Test'], ascending=False)\n",
    "for col in textMatching.columns:\n",
    "    if textMatching[col].dtype == \"float64\":\n",
    "        textMatching[col] = textMatching[col].astype(int)\n",
    "\n",
    "# Append total row \n",
    "textMatchingWithSumRow = appendSumRow(textMatching,['Project','SP','R','P'])\n",
    "textMatchingWithSumRow.to_csv('Result/TextBasedMatchingResult.csv',index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4) Top Most Exceptions in Flaky and True Failures. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 583/583 [00:05<00:00, 108.97it/s]\n"
     ]
    }
   ],
   "source": [
    "fullResult = []\n",
    "for log in tqdm(logs):\n",
    "    if (os.path.getsize(log) >0):\n",
    "        logXML = readXMLFile(log)\n",
    "        test_name = log.rsplit('/',1)[1].split('summary-of-')[1].rsplit('.xml')[0]\n",
    "        mutantsFailures = getmutantsFailures(logXML,test_name,test_name.rsplit('.',1)[0])\n",
    "        \n",
    "        testFailures = {}\n",
    "        for failure in logXML.iter('test'):\n",
    "            perProject = []\n",
    "            Failure = getTestFailure(failure,test_name,test_name.rsplit('.',1)[0])\n",
    "            k = failure.find('test_name').attrib['project']+'|'+failure.find('test_name').attrib['id']+'|'+failure.find('test_name').attrib['frequency']\n",
    "            testFailures[k] =Failure\n",
    "\n",
    "\n",
    "        setTestFailures = getSetOfFailures(testFailures) # This to get the set of failures ... \n",
    "\n",
    "        if (len(mutantsFailures)>0 and len(setTestFailures)>0):\n",
    "            project = [k for k in setTestFailures.keys()][0].split('|')[0]\n",
    "            # This is for Flaky failures \n",
    "            for failureKey, flakyFailure in setTestFailures.items():\n",
    "                exception = flakyFailure.split('|#|')[0]\n",
    "                exceptionFreq = int(failureKey.rsplit('|',1)[1])\n",
    "\n",
    "                if (flakyFailure in mutantsFailures or exceptionFreq==1):\n",
    "                    fullResult.append([project,test_name,exception,'WithStacktraces','FN',exceptionFreq])\n",
    "                else:\n",
    "                    fullResult.append([project,test_name,exception,'WithStacktraces','TP',exceptionFreq])\n",
    "\n",
    "                # Without stacktraces \n",
    "                mutantsExceptions = [m.split('|#|')[0] for m in mutantsFailures]    \n",
    "\n",
    "                if (exception in mutantsExceptions or exceptionFreq ==1):\n",
    "                    fullResult.append([project,test_name,exception,'WithOutStacktraces','FN',exceptionFreq])\n",
    "                else:\n",
    "                    fullResult.append([project,test_name,exception,'WithOutStacktraces','TP',exceptionFreq])\n",
    "\n",
    "\n",
    "            # This is for non-flaky failures ... \n",
    "            for mutantFail in mutantsFailures:\n",
    "                mutantException = mutantFail.split('|#|')[0]\n",
    "                \n",
    "                if (mutantFail in setTestFailures.values()):\n",
    "                    fullResult.append([project,test_name,mutantException,'WithStacktraces','FP',1])\n",
    "                else:\n",
    "                    fullResult.append([project,test_name,mutantException,'WithStacktraces','TN',1])\n",
    "\n",
    "                # Without stacktraces \n",
    "                failureException = [s.split('|#|')[0] for s in setTestFailures.values()]    \n",
    "\n",
    "                if (mutantException in failureException):\n",
    "                    fullResult.append([project,test_name,mutantException,'WithOutStacktraces','FP',1])\n",
    "                else:\n",
    "                    fullResult.append([project,test_name,mutantException,'WithOutStacktraces','TN',1])\n",
    "\n",
    "fullResult_df = pd.DataFrame(fullResult,columns=['Project','Test','Exception','CompareBy','Tag','Freq'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get most exceptions in both flaky and non-flaky failures .. \n",
    "\n",
    "oneTypeData = fullResult_df[fullResult_df['CompareBy']==\"WithOutStacktraces\"]\n",
    "\n",
    "uniqueExceptions = {}\n",
    "for exception in oneTypeData['Exception'].unique():\n",
    "    uniqueExceptions[exception] = oneTypeData[oneTypeData['Exception']==exception]['Freq'].sum()\n",
    "\n",
    "# Get top most exception\n",
    "topTenException = dict(sorted(uniqueExceptions.items(), key=lambda x: x[1], reverse=True)[:10])\n",
    "\n",
    "summaryExceptions = []\n",
    "for k,v in topTenException.items():        \n",
    "        perExceptionwithStacktrace = fullResult_df[(fullResult_df['Exception'] == k) & (fullResult_df['CompareBy']=='WithStacktraces')]\n",
    "\n",
    "        project_num = len(perExceptionwithStacktrace['Project'].unique())\n",
    "        test_num = len(perExceptionwithStacktrace['Test'].unique())\n",
    "\n",
    "        total_failures = perExceptionwithStacktrace['Freq'].sum()\n",
    "        tp = perExceptionwithStacktrace[perExceptionwithStacktrace['Tag']=='TP']['Freq'].sum()\n",
    "        tpTests = len(perExceptionwithStacktrace[perExceptionwithStacktrace['Tag']=='TP']['Test'].unique())\n",
    "        tpProject = len(perExceptionwithStacktrace[perExceptionwithStacktrace['Tag']=='TP']['Project'].unique())\n",
    "\n",
    "        fn = perExceptionwithStacktrace[perExceptionwithStacktrace['Tag']=='FN']['Freq'].sum()\n",
    "        fnTests = len(perExceptionwithStacktrace[perExceptionwithStacktrace['Tag']=='FN']['Test'].unique())\n",
    "        fnProject = len(perExceptionwithStacktrace[perExceptionwithStacktrace['Tag']=='FN']['Project'].unique())\n",
    "        \n",
    "        fp = perExceptionwithStacktrace[perExceptionwithStacktrace['Tag']=='FP']['Freq'].sum()\n",
    "        fpTests = len(perExceptionwithStacktrace[perExceptionwithStacktrace['Tag']=='FP']['Test'].unique())\n",
    "        fpProject = len(perExceptionwithStacktrace[perExceptionwithStacktrace['Tag']=='FP']['Project'].unique())\n",
    "\n",
    "        tn = perExceptionwithStacktrace[perExceptionwithStacktrace['Tag']=='TN']['Freq'].sum()\n",
    "        tnTests = len(perExceptionwithStacktrace[perExceptionwithStacktrace['Tag']=='TN']['Test'].unique())\n",
    "        tnProject = len(perExceptionwithStacktrace[perExceptionwithStacktrace['Tag']=='TN']['Project'].unique())\n",
    "\n",
    "\n",
    "        perExceptionwithoutStacktraces = fullResult_df[(fullResult_df['Exception'] == k) & (fullResult_df['CompareBy']=='WithOutStacktraces')]\n",
    "\n",
    "        tp1 = perExceptionwithoutStacktraces[perExceptionwithoutStacktraces['Tag']=='TP']['Freq'].sum()\n",
    "        tp1Tests = len(perExceptionwithoutStacktraces[perExceptionwithoutStacktraces['Tag']=='TP']['Test'].unique())\n",
    "        tp1Project = len(perExceptionwithoutStacktraces[perExceptionwithoutStacktraces['Tag']=='TP']['Project'].unique())\n",
    "        \n",
    "        fn1 = perExceptionwithoutStacktraces[perExceptionwithoutStacktraces['Tag']=='FN']['Freq'].sum()\n",
    "        fn1Tests = len(perExceptionwithoutStacktraces[perExceptionwithoutStacktraces['Tag']=='FN']['Test'].unique())\n",
    "        fn1Project = len(perExceptionwithoutStacktraces[perExceptionwithoutStacktraces['Tag']=='FN']['Project'].unique())\n",
    "        \n",
    "        fp1 = perExceptionwithoutStacktraces[perExceptionwithoutStacktraces['Tag']=='FP']['Freq'].sum()\n",
    "        fp1Tests = len(perExceptionwithoutStacktraces[perExceptionwithoutStacktraces['Tag']=='FP']['Test'].unique())\n",
    "        fp1Project = len(perExceptionwithoutStacktraces[perExceptionwithoutStacktraces['Tag']=='FP']['Project'].unique())\n",
    "        \n",
    "        tn1 = perExceptionwithoutStacktraces[perExceptionwithoutStacktraces['Tag']=='TN']['Freq'].sum()\n",
    "        tn1Tests = len(perExceptionwithoutStacktraces[perExceptionwithoutStacktraces['Tag']=='TN']['Test'].unique())\n",
    "        tn1Project = len(perExceptionwithoutStacktraces[perExceptionwithoutStacktraces['Tag']=='TN']['Project'].unique())\n",
    "\n",
    "        summaryExceptions.append([k,\n",
    "                                  project_num,\n",
    "                                  test_num,\n",
    "                                  tp+fp+fn+tn,\n",
    "                                  tn+fp,\n",
    "                                  fn+tp,\n",
    "                                  tp,\n",
    "                                  tpTests,\n",
    "                                  tpProject,\n",
    "                                  fn,\n",
    "                                  fnTests,\n",
    "                                  fnProject,\n",
    "                                  fp,\n",
    "                                  fpTests,\n",
    "                                  fpProject,\n",
    "                                  tn,\n",
    "                                  tnTests,\n",
    "                                  tnProject,\n",
    "                                  tp1,\n",
    "                                  tp1Tests,\n",
    "                                  tp1Project,\n",
    "                                  fn1,\n",
    "                                  fn1Tests,\n",
    "                                  fn1Project,\n",
    "                                  fp1,\n",
    "                                  fp1Tests,\n",
    "                                  fp1Project,\n",
    "                                  tn1,\n",
    "                                  tn1Tests,\n",
    "                                  tn1Project\n",
    "                                  ])\n",
    "\n",
    "\n",
    "# t refers to the total number of tests (e.g. tTP : the number of tests that have at least on TP failure)\n",
    "# p refers to the total number of project (e.g. tTP : the number of projects that have at least on TP failure)\n",
    "# _noTrace refers to matching without considering the stacktraces \n",
    "\n",
    "summaryExceptions_df = pd.DataFrame(summaryExceptions,columns=['Exception','#Projects','#Tests','TotalFailures','True','Flaky','TP','tTP','pTP','FN','tFN','pFN','FP','tFP','pFP','TN','tTN','pTN','TP_noTraces','tTP_noTraces','pTP_noTraces','FN_noTraces','tFN_noTraces','pFN_noTraces','FP_noTraces','tFP_noTraces','pFP_noTraces','TN_noTraces','tTN_noTraces','pTN_noTraces'])\n",
    "\n",
    "\n",
    "# Final Result .. \n",
    "\n",
    "finalShapeResultColumns =  ['Exception', '#Projects', '#Tests', 'TotalFailures','True','Flaky', 'TP','FN', 'FP','TN','tTP','tFN', 'tFP', 'tTN', 'TP_noTraces','FN_noTraces',  'FP_noTraces', 'TN_noTraces', 'tTP_noTraces', 'tFN_noTraces',  'tFP_noTraces',     'tTN_noTraces']\n",
    "updatedSummaryExceptions_df = summaryExceptions_df[finalShapeResultColumns]\n",
    "\n",
    "updatedSummaryExceptions_df.to_csv(output+'/TopMostExceptions.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
