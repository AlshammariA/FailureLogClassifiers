{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statistics\n",
    "import operator\n",
    "from collections import Counter\n",
    "from pathlib import Path\n",
    "import xml.etree.ElementTree as ET\n",
    "import filecmp\n",
    "from lxml import etree\n",
    "import subprocess\n",
    "import os\n",
    "import sklearn as sk\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import classification_report, f1_score, precision_score,recall_score, confusion_matrix,precision_recall_fscore_support\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.tree import export_text\n",
    "import math\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from tqdm import tqdm\n",
    "from sklearn import tree\n",
    "from functools import reduce\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFilesByStartsWith(fileDir,starts):\n",
    "    filesList = []\n",
    "    for path, subdirs, files in os.walk(fileDir):\n",
    "        for file in files:\n",
    "            if (file.startswith(starts)):\n",
    "                filesList.append(os.path.join(path,file))\n",
    "    return filesList\n",
    "\n",
    "def readXMLFile(filePath):\n",
    "    parser = etree.XMLParser(strip_cdata=False,recover=True)\n",
    "    with open(filePath, \"rb\") as source:\n",
    "        tree = etree.parse(source, parser=parser)\n",
    "    xmlroot = tree.getroot()\n",
    "    return xmlroot\n",
    "\n",
    "def find_index_starts_with(stacktraces, stoppedLines):\n",
    "    index = next((index for index, element in enumerate(stacktraces) if any(element.startswith(prefix) for prefix in stoppedLines)), -1)\n",
    "    return index\n",
    "\n",
    "def remove_elements_starts_with(stacktraces, removedLines):\n",
    "    return [element for element in stacktraces if not any(element.startswith(prefix) for prefix in removedLines)]\n",
    "\n",
    "def processStackTraceLines(lines):\n",
    "    newListofLines = []\n",
    "    execludedLines = ['java.lang.invoke.LambdaForm','sun.reflect.GeneratedMethodAccessor','sun.reflect.GeneratedConstructorAccessor','com.sun.proxy.']\n",
    "    for line in lines:\n",
    "        newLine = line.replace('\\t','')\n",
    "        newLine = newLine.replace('\\n','')\n",
    "        if not any(newLine.startswith(e) for e in execludedLines):\n",
    "            newListofLines.append(newLine)\n",
    "    return newListofLines\n",
    "\n",
    "def getSummaryFilesByProjectName(files):\n",
    "    result = {}\n",
    "    for file in files:\n",
    "        if (os.path.getsize(file) >0):\n",
    "            xmlFile = readXMLFile(file)\n",
    "            if (len(xmlFile.findall('.//test'))>0):\n",
    "                result[file] = xmlFile.findall('.//test')[0].find('test_name').attrib['project']\n",
    "    return result\n",
    "\n",
    "def getStackTraceTokens(listOfStackTraceLines):\n",
    "    tokens  = []\n",
    "    for line in listOfStackTraceLines:\n",
    "        firstPart = line.rsplit('(',1)[0].split('.')\n",
    "        javaFilePart = line.rsplit('(',1)[1].split(')')[0]\n",
    "        if ('.java:' in javaFilePart):\n",
    "            # #This part when we execlude the java as file extension and line number \n",
    "            # secondPart = javaFilePart.split('.java:')[0]\n",
    "            # tokens = tokens + firstPart\n",
    "            # tokens.append(secondPart)\n",
    "\n",
    "            #This part when we INCLUDE the java as file extension and line number \n",
    "            secondPart = javaFilePart.split('.java:')[0] + ' java ' +javaFilePart.split('.java:')[1]\n",
    "            tokens = tokens + firstPart\n",
    "            tokens.append(secondPart)\n",
    "        else:\n",
    "            secondPart = javaFilePart.split(' ')\n",
    "            tokens = tokens + firstPart + secondPart\n",
    "    return tokens\n",
    "\n",
    "def collectTokens(testFiles,project):\n",
    "\n",
    "    # KEy = TestName + '|#|' + failureType + '|#|' +status + '|#|' + ID\n",
    "    # Value = Tokens list (including ExceptionType)\n",
    "    \n",
    "    execludedLines = ['java.lang.invoke.LambdaForm','sun.reflect.GeneratedMethodAccessor','sun.reflect.GeneratedConstructorAccessor','com.sun.proxy.']\n",
    "    stoppedLines = ['junit.framework.TestCase.runBare(','sun.reflect.NativeMethodAccessorImpl.invoke0(','org.junit.rules.ExternalResource$1.evaluate(']\n",
    "\n",
    "    resultPerProject = {}\n",
    "    xmlNodeTypes = ['test','mutant']\n",
    "    for testFile in testFiles.keys():\n",
    "        testRoot = readXMLFile(testFile)\n",
    "        for rootType in xmlNodeTypes:\n",
    "            for failure in testRoot.findall('.//'+rootType):\n",
    "                if (rootType == 'test'):\n",
    "                    failureID = failure.find(rootType+'_name').attrib['id']\n",
    "                    failureFreq = failure.find(rootType+'_name').attrib['frequency']\n",
    "                else:\n",
    "                    failureID = failure.find(rootType+'_name').attrib['mutant_id']\n",
    "                    failureFreq = '1'\n",
    "                \n",
    "                testName = failure.find(rootType+'_name').text.replace(\" \", \"\").replace(\"\\t\", \"\").replace(\"\\n\", \"\")\n",
    "                failureStatus = failure.find(rootType+'_name').attrib['status']\n",
    "                if (failureStatus == 'FLAKY' and rootType == 'mutant'):\n",
    "                    pass\n",
    "                else:\n",
    "                    failureException = failure.find(rootType+'_exception').text.split(' ')\n",
    "                    failureStackTraceLines = [line.text.replace(\" \", \"\").replace(\"\\t\", \"\").replace(\"\\n\", \"\") for line in  failure.iter('line')]\n",
    "\n",
    "                    # Update: June 2023. if the stacktrace lines does not have the test name and the class name, stop in the first occurance of the stoppedLines\n",
    "                    if(all(not any(item.startswith(prefix) for prefix in [testName,testName.rsplit('.',1)[0]]) for item in failureStackTraceLines)):\n",
    "                        ind = find_index_starts_with(failureStackTraceLines, stoppedLines)\n",
    "                        if (ind > 0):\n",
    "                            failureStackTraceLines = failureStackTraceLines[:ind]\n",
    "\n",
    "                    # processedLines = processStackTraceLines(failureStackTraceLines)\n",
    "                    # remove non-determinist lines (Jon)\n",
    "                    processedLines = remove_elements_starts_with(failureStackTraceLines, execludedLines)\n",
    "\n",
    "                    stackTraceTokens  = getStackTraceTokens(processedLines)\n",
    "\n",
    "                    resultPerProject[project+'|#|'+testName+'|#|'+rootType+'|#|'+ failureID+'|#|'+failureFreq+ '|#|'+failureStatus] = ' '.join(stackTraceTokens+failureException)\n",
    "        \n",
    "    return resultPerProject\n",
    "\n",
    "\n",
    "def TfidfFailuresVectorizer(failures):\n",
    "    FailuresVect = TfidfVectorizer(max_features=300)\n",
    "    FailVec = FailuresVect.fit_transform(failures)\n",
    "    tokens_names = FailuresVect.get_feature_names()\n",
    "    result = FailVec.todense()\n",
    "    resultList = result.tolist()\n",
    "    resultDF = pd.DataFrame(resultList,columns=tokens_names)\n",
    "\n",
    "    return resultDF\n",
    "\n",
    "def replicate_row(row):\n",
    "    repeated_series = [row.drop('repeat_count')] * (row['repeat_count'] - 1 + 1) \n",
    "    return pd.concat(repeated_series, axis=1).transpose()\n",
    "\n",
    "\n",
    "def generateUniqueId(data,uniqueColumns):\n",
    "    data['FailurePrimaryKey'] = \"NA\"\n",
    "    for index, row in data.iterrows():\n",
    "        pKey = []\n",
    "        for col in uniqueColumns:\n",
    "            pKey.append(str(row[col]))\n",
    "        data.loc[index, 'FailurePrimaryKey'] = '|#|'.join(pKey)\n",
    "    return data\n",
    "\n",
    "\n",
    "def get_scores (tn,fp,fn,tp):\n",
    "    if(tp==0):\n",
    "        accuracy = (tp+tn)/(tn+fp+fn+tp)\n",
    "        Precision = 0\n",
    "        Recall = 0\n",
    "        F1 = 0    \n",
    "    else:\n",
    "        accuracy = (tp+tn)/(tn+fp+fn+tp)\n",
    "        Precision = tp/(tp+fp)\n",
    "        Recall = tp/(tp+fn)\n",
    "        F1 = 2*((Precision*Recall)/(Precision+Recall))    \n",
    "    return accuracy, F1, Precision, Recall\n",
    "\n",
    "def PredictFailure(data,data_target,project,targetClass):\n",
    "    if ('index' in data.columns):\n",
    "        data = data.drop(['index'], axis=1)\n",
    "\n",
    "    # The type of k-fold is StratifiedKFold to ensure each fold has flaky failures. \n",
    "    fold = StratifiedKFold(n_splits=10,shuffle=True)\n",
    "\n",
    "    TN = FP = FN = TP = 0\n",
    "    for train_index, test_index in fold.split(data,data_target):\n",
    "        x_train, x_test = data.iloc[list(train_index)], data.iloc[list(test_index)]\n",
    "        y_train, y_test = data_target.iloc[list(train_index)], data_target.iloc[list(test_index)]\n",
    "\n",
    "        tfidf = TfidfVectorizer()\n",
    "        x_trained = tfidf.fit_transform(x_train['Tokens'])\n",
    "        x_tested = tfidf.transform(x_test['Tokens'])\n",
    "\n",
    "        clf = SVC()\n",
    "        clf.fit(x_trained, y_train)\n",
    "        y_pred = clf.predict(x_tested)\n",
    "        if (targetClass == \"FLAKY\"):\n",
    "            tn, fp, fn, tp = confusion_matrix(y_test, y_pred, labels=['KILLED','FLAKY']).ravel()\n",
    "        else:\n",
    "            tn, fp, fn, tp = confusion_matrix(y_test, y_pred, labels=['mutant','test']).ravel()\n",
    "        TN = TN + tn\n",
    "        FP = FP + fp\n",
    "        FN = FN + fn\n",
    "        TP = TP + tp\n",
    "    \n",
    "    accuracy, F1, Precision, Recall = get_scores (TN,FP,FN,TP)\n",
    "    return [project,TN+FP+FN+TP,TP,FN,FP,TN,Precision*100, Recall*100,F1*100]\n",
    "\n",
    "def getFilesByEndsWith(fileDir,ends):\n",
    "    filesList = []\n",
    "    for path, subdirs, files in os.walk(fileDir):\n",
    "        for file in files:\n",
    "            if (file.endswith(ends)):\n",
    "                filesList.append(os.path.join(path,file))\n",
    "    return filesList"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = 'Result'\n",
    "DatasetDir = 'Path-to-dataset' # change this to the path of our dataset\n",
    "parser = etree.XMLParser(strip_cdata=False,recover=True)\n",
    "\n",
    "\n",
    "csvFiles = getFilesByEndsWith(DatasetDir,'FeaturesPerTest.csv') # use FeaturesPerTestAll.csv to count all failures .. \n",
    "ignoreTests = []\n",
    "for c in csvFiles:\n",
    "    c_data = pd.read_csv(c)\n",
    "    if (len(c_data)<1):\n",
    "        ignoreTests.append(c.rsplit('/')[-2]+'.xml')\n",
    "\n",
    "\n",
    "allSummaryFiles = getFilesByStartsWith(DatasetDir,'summary-of-')\n",
    "allSummaryFilesUpdated = [item for item in allSummaryFiles if not any(item.endswith(prefix) for prefix in ignoreTests)]\n",
    "\n",
    "\n",
    "testsByProjectNames = getSummaryFilesByProjectName(allSummaryFilesUpdated)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "minFlaky = 10\n",
    "tfidfResult = []\n",
    "for project in set(testsByProjectNames.values()):\n",
    "        # get failures per projects .. \n",
    "        failuresPErProject = {k:v for k,v in testsByProjectNames.items() if v == project}\n",
    "\n",
    "        tokensPerProjectsUpdated = collectTokens(failuresPErProject,project)\n",
    "\n",
    "        TakensDF = []\n",
    "        for k,v in tokensPerProjectsUpdated.items():\n",
    "            perFailure = k.split('|#|')\n",
    "            perFailure.append(v)\n",
    "            TakensDF.append(perFailure)\n",
    "        \n",
    "        tfidfPerProjectNoDuplicates = pd.DataFrame(TakensDF,columns=['Project','Test','FailureType','FailureId','FailureFreq','FailureStatus','Tokens'])\n",
    "\n",
    "        flakyTests = tfidfPerProjectNoDuplicates[tfidfPerProjectNoDuplicates['FailureType']=='test']['Test'].unique().tolist()\n",
    "        mutants = tfidfPerProjectNoDuplicates[tfidfPerProjectNoDuplicates['FailureType']=='mutant']['Test'].unique().tolist()\n",
    "        testWithNoMutants = [e for e in flakyTests if e in mutants]\n",
    "        tfidfPerProjectNoDuplicatesWithMutants = tfidfPerProjectNoDuplicates[tfidfPerProjectNoDuplicates['Test'].isin(testWithNoMutants)]\n",
    "        \n",
    "        tfidfPerProject = tfidfPerProjectNoDuplicatesWithMutants.loc[tfidfPerProjectNoDuplicatesWithMutants.index.repeat(tfidfPerProjectNoDuplicatesWithMutants['FailureFreq'])].reset_index(drop=True)\n",
    "        \n",
    "\n",
    "        if (len(tfidfPerProject[tfidfPerProject['FailureStatus']=='FLAKY'])>minFlaky):\n",
    "            tfidfProjectResult = PredictFailure(tfidfPerProject[['Tokens']],tfidfPerProject['FailureStatus'],project,'FLAKY')\n",
    "            tfidfResult.append(tfidfProjectResult)\n",
    "\n",
    "tfidfResult_DF = pd.DataFrame(tfidfResult,columns=['Project','Total','TP','FN','FP','TN','P','R','F1'])\n",
    "\n",
    "tfidfResult_DF.to_csv(output+'/TFIDF.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
