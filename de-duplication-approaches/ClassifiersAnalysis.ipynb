{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Flaky VS True Failures Classification Results "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import csv\n",
    "import re\n",
    "import xml.etree.ElementTree as ET\n",
    "from xml.etree.ElementTree import Element\n",
    "import filecmp\n",
    "from lxml import etree\n",
    "from pathlib import Path\n",
    "import base64\n",
    "import unicodedata\n",
    "from tqdm import tqdm\n",
    "import glob\n",
    "import statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = 'Result'\n",
    "projectNames = {\"spring-boot\":\"spring-projects-spring-boot\",\n",
    "                \"alluxio\" : \"Alluxio-alluxio\",\n",
    "                \"http-request\": \"kevinsawicki-http-request\",\n",
    "                \"hbase\" : \"apache-hbase\",\n",
    "                \"ambari\": \"apache-ambari\",\n",
    "                \"java-webSocket\" : \"tootallnate-java-websocket\",\n",
    "                \"wildfly\": \"wildfly-wildfly\",\n",
    "                \"okhttp\":\"square-okhttp\",\n",
    "                \"hector\" : \"hector-client-hector\",\n",
    "                \"wro4j\": \"wro4j-wro4j\",\n",
    "                \"incubator-dubbo\" : \"apache-incubator-dubbo\",\n",
    "                \"logback\" : \"qos-ch-logback\",\n",
    "                \"activiti\" : \"activiti-activiti\",\n",
    "                \"httpcore\" : \"apache-httpcore\",\n",
    "                \"commons-exec\" : \"apache-commons-exec\",\n",
    "                \"io-undertow\" : \"undertow-io-undertow\",\n",
    "                \"orbit\" : \"orbit-orbit\",\n",
    "                \"assertj-core\" : \"assertj-core\",\n",
    "                \"achilles\" : \"doanduyhai-Achilles\",\n",
    "                \"handlebars.java\" : \"handlebars.java\",\n",
    "                \"elastic-job-lite\" : \"elasticjob-elastic-job-lite\",\n",
    "                \"zxing\" : \"zxing-zxing\",\n",
    "                \"ninja\" : \"ninja-ninja\"}\n",
    "\n",
    "output = 'Result'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DT = pd.read_csv('Result/DT_FinalClassifierResult.csv',index_col=False)\n",
    "NB = pd.read_csv('Result/NB_FinalClassifierResult.csv',index_col=False)\n",
    "tfidf = pd.read_csv('Result/TFIDF.csv',index_col=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "targetResult = ['TP', 'FN','FP', 'TN', 'P', 'R', 'F1']\n",
    "allResult = {}\n",
    "for project in DT['Project'].unique():\n",
    "    # if (project != \"alluxio\"):\n",
    "        DT_balance = DT[(DT['Project']==project) & (DT['ResultTag']=='Balance+Duplicate+FailuresWithMutants')]\n",
    "        DT_NotBalance = DT[(DT['Project']==project) & (DT['ResultTag']=='NotBalance+Duplicate+FailuresWithMutants')]\n",
    "        NB_balance = NB[(NB['Project']==project) & (NB['ResultTag']=='Balance+Duplicate+FailuresWithMutants')]\n",
    "        NB_NotBalance = NB[(NB['Project']==project) & (NB['ResultTag']=='NotBalance+Duplicate+FailuresWithMutants')]\n",
    "        tfidfperProject = tfidf[tfidf['Project']==project]\n",
    "        \n",
    "\n",
    "        # iterate over the result\n",
    "        dataset = {'DT|Balance':DT_balance,'DT|NotBalance':DT_NotBalance, 'NB|Balance':NB_balance, 'NB|NotBalance': NB_NotBalance,'tfidf|None':tfidfperProject}\n",
    "        for k,d in dataset.items():\n",
    "            if (len(d)>0):\n",
    "                resultPerProject = []\n",
    "                for c in targetResult:\n",
    "                    resultPerProject.append(int(d[c].tolist()[0]))\n",
    "\n",
    "                allResult[project+'|'+k] = '|'.join([str(i) for i in resultPerProject])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "projects = [k.split('|')[0] for k in allResult.keys()]\n",
    "finalResultAllProjects = []\n",
    "useBalance = False\n",
    "thold = 0.10\n",
    "for p in set(projects):\n",
    "    # if (p == 'alluxio'):\n",
    "        perProjectDTBalance = {k:v for k,v in allResult.items() if k ==(p+'|DT|Balance')}\n",
    "        perProjectDTNotBalance = {k:v for k,v in allResult.items() if k ==(p+'|DT|NotBalance')}\n",
    "        perProjectTFIDF = {k:v for k,v in allResult.items() if k ==(p+'|tfidf|None')}\n",
    "        \n",
    "        \n",
    "\n",
    "        perProjectResult = []\n",
    "        perProjectResult.append(p)\n",
    "        if (useBalance):\n",
    "            ff = sum([int(x) for x in list(perProjectDTBalance.values())[0].split('|')][:2])\n",
    "            tf = sum([int(x) for x in list(perProjectDTBalance.values())[0].split('|')][2:4])\n",
    "            if (tf + ff >0):\n",
    "                if (tf/ff < thold or ff/tf < thold):\n",
    "                    perProjectResult.extend(list(perProjectDTBalance.values())[0].split('|') if len(perProjectDTBalance)>0 else [0,0,0,0,0,0,0])\n",
    "                else:\n",
    "                    perProjectResult.extend(list(perProjectDTNotBalance.values())[0].split('|') if len(perProjectDTNotBalance)>0 else [0,0,0,0,0,0,0])\n",
    "                perProjectResult.extend(list(perProjectTFIDF.values())[0].split('|') if len(perProjectTFIDF)>0 else [0,0,0,0,0,0,0])\n",
    "            else:\n",
    "                perProjectResult.extend([0,0,0,0,0,0,0,0,0,0,0,0,0,0])\n",
    "        else:\n",
    "            perProjectResult.extend(list(perProjectDTNotBalance.values())[0].split('|') if len(perProjectDTNotBalance)>0 else [0,0,0,0,0,0,0])\n",
    "            perProjectResult.extend(list(perProjectTFIDF.values())[0].split('|') if len(perProjectTFIDF)>0 else [0,0,0,0,0,0,0])\n",
    "        \n",
    "        # Add Total and total flaky and non true failures\n",
    "        TotalFailures = sum([int(perProjectResult[a]) for a in [1,2,3,4]])\n",
    "        OnlyFlaky = sum([int(perProjectResult[a]) for a in [1,2]])\n",
    "        non_Flaky = sum([int(perProjectResult[a]) for a in [3,4]])\n",
    "\n",
    "        perProjectResult.insert(1,OnlyFlaky)\n",
    "        perProjectResult.insert(1,non_Flaky)\n",
    "        perProjectResult.insert(1,TotalFailures)\n",
    "        finalResultAllProjects.append(perProjectResult)\n",
    "\n",
    "allProject_df = pd.DataFrame(finalResultAllProjects,columns=['Project','TotalFailures','TotalNonFlaky','TotalFlaky','TP_FailureLog','FN__FailureLog','FP__FailureLog','TN_FailureLog','P_FailureLog','R_FailureLog','F_FailureLog','TP_TFIDF','FN_TFIDF','FP_TFIDF','TN_TFIDF','P_TFIDF','R_TFIDF','F1_TFIDF'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# order by the total number of tests\n",
    "resultTests = pd.read_csv(output+'/TextBasedMatchingResult.csv',index_col=False)\n",
    "\n",
    "projectsTests = resultTests[['Project','Test']]\n",
    "projectsTests = projectsTests.dropna()\n",
    "merged_df = pd.merge(allProject_df, projectsTests, on='Project', how='outer')\n",
    "\n",
    "merged_df = merged_df.sort_values(by=['Test'], ascending=False).reset_index()\n",
    "merged_df = merged_df[['Project','Test','TotalFailures','TotalFlaky','TotalNonFlaky','TP_FailureLog','FN__FailureLog','FP__FailureLog','TN_FailureLog','P_FailureLog','R_FailureLog','F_FailureLog','TP_TFIDF','FN_TFIDF','FP_TFIDF','TN_TFIDF','P_TFIDF','R_TFIDF','F1_TFIDF']]\n",
    "\n",
    "# convert to int tp get the sum then\n",
    "columnList = ['Test','TotalFailures','TotalFlaky','TotalNonFlaky','TP_FailureLog','FN__FailureLog','FP__FailureLog','TN_FailureLog','P_FailureLog','R_FailureLog','F_FailureLog','TP_TFIDF','FN_TFIDF','FP_TFIDF','TN_TFIDF','P_TFIDF','R_TFIDF','F1_TFIDF']\n",
    "for c in columnList:\n",
    "    merged_df[c] = merged_df[c].astype(int)\n",
    "\n",
    "merged_df = merged_df[merged_df['TotalFailures']>0]\n",
    "sum_row = merged_df[columnList].sum().rename('Total')\n",
    "merged_df = merged_df.append(sum_row, ignore_index=True)\n",
    "\n",
    "\n",
    "merged_df.to_csv(output+'/FailureLog_VS_TFIDF.csv',index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
